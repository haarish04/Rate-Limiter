A simple txt file to keep track of my progress and how I designed this application

Initially tried to setup a web server using elysia.js just as a way of experimenting new tools but faced some issues when I tried setting it up and hence decided to go for the classic node + express
A simple express app was hosted on port 3000 and some basic routes were setup.

The next step was to setup postman to test the API endpoints were working or not.
Setup postman extension on vscode for testing. Created new collection called testing to test all the routes. With this the basic web server has been hosted with basic routes along with Postman testing setup.
Running performance tests is not available in the extension, so had to boot up the Postman client for it.

Setup all the endpoints in one collection and run performance test by setting up the number of virtual users and time duration. To stress test the API, ramp up the virtual users.
Rther then using type: module in the package.json file, if I leave it as default, it assumes the .mjs/.cjs extension. In order to import packages I need to use the require statement instead of import.

Now moving onto the rate limiting algorithm, there are a number of algorithms to pick from. I will be trying out a few of them such as:

Token Bucket: Tokens are added to a ‘bucket’ at a fixed rate. The bucket has a fixed capacity. When a request is made it will only be accepted if there are enough tokens in the bucket. Tokens are removed from the bucket when a request is accepted.
Fixed window counter - Record the number of requests from a sender occurring in the rate limit’s fixed time interval, if it exceeds the limit the request is rejected.
Sliding window counter - Similar to the fixed window, but each request is timestamped and the window slides.

<---------------------------------------------------------------->

The first implementation is using token bucket algo. 

There is a ‘bucket’ that has capacity for N tokens. Usually this is a bucket per user or IP address.
Every time period a new token is added to the bucket, if the bucket is full the token is discarded.
When a request arrives and the bucket contains tokens, the request is handled and a token is removed from the bucket.
When a request arrives and the bucket is empty, the request is declined.

In the first part of the implementation, we are not dealing with IP addresses and just using the virtual users as individual users during testing in postman

First round of testing: Performance testing with ramp up virtual users upto 50 for 5 mins. Error rate was 0, the problem being, when there is excess load, I am not throttling requests and instead sending back response with "Overload".
This is not considered as error since a response is generated. In order to truly test the throttling, I need to send response code of error
Fixed the code to call the function appropriately and also to generate error status code. This was tested: spike pattern to go upto 60 users for 10 secs out of 2 mins of testing
Results visible in Token Bucket testing figure

Another thing to keep in mind is that postman lets us configure the number of users not specifically no. of requests per second, considering a response takes on average 3-4 ms. Per second there could be upto 250-333 requests per second. But at around 12 -13 requests per second, you can observe requests being failed.
<---------------------------------------------------------------->

The next implementation is using fixed window counter algorithm

A window size of N seconds is used to track the request rate. Each incoming request increments the counter for the window.
If the counter exceeds a threshold, the request is discarded.
The windows are typically defined by the floor of the current timestamp, so 17:47:13 with a 60 second window length, would be in the 17:47:00 window.

To implement this, I used date.now() at every request and floor it to the nearest second. My implementation is handling x requests per second so I keep track of the nearest second.
For every request I also keep track of exact time and see if it falls under which second (which window) if count is 0 for that window, throttle the request, else accept it.
If request minus window time is grater than 1 second, it falls under new window, refresh counter and start new window.

<---------------------------------------------------------------->

The next algorithm is the sliding window log method.

Tracking a time stamped log for each consumer request. These logs are usually stored in a hash set or table that is sorted by time.
Logs with timestamps beyond a threshold are discarded.
When a new request comes in, we calculate the sum of logs to determine the request rate.
If the request when added to the log would exceed the threshold rate, then it is declined.

The advantage of this algorithm is that it does not suffer from the boundary conditions of fixed windows. The limit will be enforced precisely and because the sliding log is tracked for each consumer, you don’t have the issue that every use can suddenly surge in requests each time a fixed window boundary passes.

The disadvantage is that it needs to store an unlimited number of logs for every request. As the size of the logs grows it can become expensive to compute the summation over all the log entries. As a result it does not scale well to handle large bursts of traffic or denial of service attacks.